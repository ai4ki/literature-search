{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCXX7LUWFmeu"
   },
   "source": [
    "# Literature Search with Semantic Scholar\n",
    " \n",
    "*Last updated: 01/21/2022*\n",
    " \n",
    "This notebook allows you to query [Semantic Scholar](https://www.semanticscholar.org). It is based on the Semantic Scholar API, which is documented [here](https://api.semanticscholar.org/graph/v1). \n",
    "\n",
    "The results of your queries are stored in different formats: an Excel- and a JSON-file with the full publication data, and a `.bib`-file with only the BibTex data for each publication (if available). You will need the JSON-files, if you later want to merge results using the notebook `Merge_Inspect_Select.ipynb`. The files are named `MySemSchol_Search_[current date_time].xlsx/.json/.bib`. You will find the files on the left navigation pane in folders named `results_excel/json/bibtex`.   \n",
    "\n",
    "**Note**: This is not an application to be used at scale! So, whether you like it or not, please use it with restraint (Semantic Scholar sets a limit of 100 requests per five minutes anyway). \n",
    "\n",
    "## Section I: Query the Semantic Scholar Database\n",
    "\n",
    "Due to the semantic search approach, the API does not support a special query syntax like Boolean operators or wildcards. Try using a natural language query or the ususal sequence of keywords instead.  \n",
    "\n",
    "Note that per query a maximum of 100 results (i.e., paper references) is returned. In case your query yielded more than 100 hits, you have to repeat the same query until you reached the desired number of results (see below for instructions on how to do this). \n",
    "\n",
    "## Section II: Perform multiple queries in one batch\n",
    "\n",
    "You can also send any number of different queries to Semantic Scholar in one batch. Go directly to Section II below for instructions on how to do this.\n",
    "\n",
    "\n",
    "## Working with Jupyter notebooks\n",
    "\n",
    "In case you are not familiar with Jupyter notebooks, this is how to go about it: In order to execute a piece of code, click inside a cell (the ones with `[]` to the left) and press Shift+Enter. Wait until the cell is done--that's when the `*` in `[]` turned into a number--and move on to the next cell.\n",
    "\n",
    "If you get inconceivable error messages or the notebook gets stuck, choose \"Restart & Clear Output\" in the \"Kernel\" dropdown-menu above.\n",
    "\n",
    "___\n",
    "**Please help us to improve this tool by [emailing us](mailto:ai4ki.dev@gmail.com?subject=ai4ki-tools:%20Semantic%20Scholar%20Search) your update ideas or error reports.**\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation: Import libraries\n",
    "*You have to excecute the following cell only once at the beginning of a session!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "id": "tclHUXzdfuug"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "sys.path.append('../')\n",
    "\n",
    "from datetime import datetime\n",
    "from os.path import join\n",
    "from ai4ki_utils.semschol_utils import *\n",
    "from ai4ki_utils.semschol_request import semschol_request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section I: Query the Semantic Scholar Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Formulate search query\n",
    "*Run the following cell to perform a single query. Enter your query in the input field that pops up below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "_tFqKbFhF3Np"
   },
   "outputs": [],
   "source": [
    "query = input('Enter query: ') \n",
    "print('Accepted query: ', query)\n",
    "# Replace spaces with proper URL encoding \n",
    "query = query.strip().replace(' ','%20')\n",
    "# Create list for storing more than 100 results\n",
    "results_store = []\n",
    "# Count number of queries for convenience later\n",
    "n_queries = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Post query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1294,
     "status": "ok",
     "timestamp": 1632155788100,
     "user": {
      "displayName": "ai4ki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfzsf3wEt__56AE_4PN8hCpiInZFjxJd2dBRcS=s64",
      "userId": "02525147809839202215"
     },
     "user_tz": -120
    },
    "id": "EAFQ3zVoFUNS",
    "outputId": "02e848e3-35a1-4d0d-f6ff-295d72f93739"
   },
   "outputs": [],
   "source": [
    "# Set the maximum number of results to be returned (absolute maximum is 100)\n",
    "limit = 100\n",
    "offset = int((n_queries - 1)*limit)\n",
    "\n",
    "# Define the fields to be returned by the API request (can be changed, see API documentation)\n",
    "FIELDS = 'title,url,authors,abstract,citationCount,externalIds,isOpenAccess,year,fieldsOfStudy' \n",
    "\n",
    "# Store query parameters in directory\n",
    "params = {\n",
    "    'offset': str(offset),\n",
    "    'limit': str(limit),\n",
    "    'fields': FIELDS\n",
    "}\n",
    "\n",
    "# URL for the Semantic Scholar API endpoint\n",
    "url='https://api.semanticscholar.org/graph/v1/paper/search?query=' + query\n",
    "\n",
    "# Make the request and fetch the data\n",
    "status, results = semschol_request(url, params)\n",
    "if status: \n",
    "    n_papers = len(results['data'])\n",
    "    print('==> Formatting publication data {beg} to {end}:'.format(beg=offset,end=n_papers + offset - 1))\n",
    "    results_form = format_semschol_data(n_papers, results)\n",
    "    results_store += results_form\n",
    "    df_tmp = pd.DataFrame(results_form) # Create dataframe for display\n",
    "    n_queries += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Preview results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview results\n",
    "n_rows = int(input('Enter number of rows to display: ')) \n",
    "print('==> Displaying first {n} rows: '.format(n=n_rows))\n",
    "\n",
    "df_tmp.head(n_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1: Show results in Semantic Scholar (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 415,
     "status": "ok",
     "timestamp": 1632142960370,
     "user": {
      "displayName": "Wes Dandey",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDbIPAXiFZU7tSahbNxI_e9ltP4InTHOnKCPt-=s64",
      "userId": "07931017761522483052"
     },
     "user_tz": -120
    },
    "id": "5fYFjQr_q4Vy",
    "outputId": "b454a39d-49a2-4d2c-e8bd-17b3582b0191"
   },
   "outputs": [],
   "source": [
    "#Get equivalent Semantic Scholar search URL\n",
    "sem_schol_url = 'https://www.semanticscholar.org/search?q=' + query + '&sort=relevance'\n",
    "sem_schol_url = sem_schol_url.replace(' ', '%20')\n",
    "print(\"Follow this link: \", sem_schol_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPAbK22Go4Rg"
   },
   "source": [
    "*If you want to export more than 100 results, repeat step 2 before moving on to Step 4!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Export publication data  \n",
    "*Note that, after running the following cell, your query results will be deleted from memory!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "KC2jUAwxauGn"
   },
   "outputs": [],
   "source": [
    "XCL_XTNSN, JSN_XTNSN, BBT_XTNSN = '.xlsx', '.json', '.bib'\n",
    "time_stamp = datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")\n",
    "outfile = \"MySemSchol_Search_\" + str(time_stamp)\n",
    "\n",
    "# Export results to EXCEL file\n",
    "df_out = pd.DataFrame(results_store)\n",
    "df_out.to_excel(join('./results_excel', outfile+XCL_XTNSN), engine='openpyxl', index=False)\n",
    "\n",
    "# Export BibTex-Data to .bib-file\n",
    "bibtex_data = '\\n\\n'.join([item['BibTex'] for item in results_store if item['BibTex'] is not None])\n",
    "with open(join('./results_bibtex',outfile+BBT_XTNSN), 'w', encoding='utf-8') as f:\n",
    "    f.write(bibtex_data)\n",
    "    \n",
    "# Export results to JSON file\n",
    "with open(join('./results_json',outfile+JSN_XTNSN), 'w', encoding='utf-8') as f:\n",
    "    json.dump(results_store, f)\n",
    "\n",
    "#Delete variables for next run\n",
    "del df_out, df_tmp, n_queries, n_papers, outfile, query, results, results_form, results_store, status, url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section II: Perform multiple queries in one batch\n",
    "\n",
    "### Step 1: Load your queries\n",
    "*Provide your queries in a `.txt`-file with one line for each query. Run the following cell to load your queries.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and read queries file\n",
    "with open('SemSchol_queries.txt', 'r', encoding='utf-8') as f:\n",
    "    user_queries = f.readlines()\n",
    "# Strip leading and trailing spaces and newline char; replace space with proper URL encoding\n",
    "queries = [q.strip().replace(' ','%20') for q in user_queries]\n",
    "for i,q in enumerate(user_queries): print('Query {}: {}'.format(i,q.strip()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Compare the queries (optional)\n",
    "*Run the following cell to get the number of papers for each query and indictaors for how a pair of queries compares for the first 100 results.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = comp_mult_queries(queries, min_match=0.7, min_rbo=0.5, p_value=0.97)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation of the RBO value:**<br>\n",
    "\n",
    "*Rank Biased Overlap (RBO) is a measure of similarity between two ranked lists, which don't necessarily share the same items. `RBO=0` means no, `RBO=1` means perfect overlap between two lists. The `p_value` is a measure of how much the first `n` results contribute to the RBO-value. We use a `p_value` of 0.97, which means that the top 10 results contribute roughly 50% to the RBO measure.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1: Discard redundant queries\n",
    "Based on the results of the comparison, you can discard queries, which return redundant results. In the first line of following cell, enter the numbers of the queries you want to discard. Then run the cell to delete the chosen queries from the list `queries`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_queries = [2,5,8]\n",
    "for d in delete_queries:\n",
    "    queries.pop(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Process the queries\n",
    "*Run the following cell to process your queries and export the ressults to Excel.<br>\n",
    "The results of each query is stored in a separate Excel-, JSON-, and BibTex-files named `MySemSchol_Search_[query i]_[current date_time].*`.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each query, set the number of papers to download.\n",
    "limit = 100\n",
    "offset = 0\n",
    "\n",
    "# Define the fields to be returned by the API request (can be changed, see API documentation)\n",
    "FIELDS = 'title,url,authors,abstract,citationCount,externalIds,isOpenAccess,year,fieldsOfStudy' \n",
    "\n",
    "# Store query parameters in directory\n",
    "params = {\n",
    "    'offset': str(offset),\n",
    "    'limit': str(limit),\n",
    "    'fields': FIELDS\n",
    "}\n",
    "\n",
    "# For each query, make the request and fetch the data\n",
    "proc_mult_queries(queries, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Semantic_Scholar_API.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:ai4ki]",
   "language": "python",
   "name": "conda-env-ai4ki-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
