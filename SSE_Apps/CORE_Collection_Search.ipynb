{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCXX7LUWFmeu"
   },
   "source": [
    "# Literature Search with CORE\n",
    " \n",
    "*Last updated: 01/21/2022*\n",
    " \n",
    "This notebook allows you to query the [CORE](https://core.ac.uk/) collection. It is based on the CORE API, which is documented [here](https://api.core.ac.uk/docs/v3). \n",
    "\n",
    "The results of your queries are stored in different formats: an Excel- and a JSON-file with the full publication data, and a `.bib`-file with only the BibTex data for each publication (if available). You will need the JSON-files, if you later want to merge results using the notebook `Merge_Inspect_Select.ipynb`. The files are named `MyCORE_Search_[current date_time].xlsx/.json/.bib`. You will find the files on the left navigation pane in folders named `results_excel/json/bibtex`.   \n",
    "\n",
    "You can also bulk download all PDFs available to your query (see Section I, Step 4).\n",
    "\n",
    "**Note**: You need an API key to use this notebook. If you don't have one, you can request one [here](https://core.ac.uk/searchAssets/api-keys/register/).\n",
    "\n",
    "## Section I: Query the CORE Collection\n",
    "CORE allows you to use special query syntax. In particular, you can use the logical binaries `OR` and `AND` (note that CORE treats a blank space as `AND`). Moreover, it is possible to use round brackets for grouping and prioritizing elements of the query, like so `(\"deep learning\" AND (applications OR models))` (make sure to wrap the entire query in brackets).\n",
    "\n",
    "You can also restrict your search to certain fields, in particular to `title`, `abstract`, or `fullText`. To do that, you have to add the field parameter to *every* search term, like so `(title:\"deep learning\" AND (abstract:applications OR abstract:models))`.     \n",
    "\n",
    "Note that per query a maximum of 100 results is returned. In case your query yielded more than 100 hits, you have to repeat the same query until you reached the desired number of results (see below for instructions on how to do this).\n",
    "\n",
    "## Section II: Perform multiple queries in one batch\n",
    "\n",
    "You can also send any number of queries to the CORE API in one batch. Go directly to Section II for instructions on how to do this.\n",
    "\n",
    "## Working with Jupyter notebooks\n",
    "\n",
    "In case you are not familiar with Jupyter notebooks, this is how to go about it: In order to execute a piece of code, click inside a cell (the ones with `[]` to the left) and press Shift+Enter. Wait until the cell is done--that's when the `*` in `[]` turned into a number--and move on to the next cell.\n",
    "\n",
    "If you get inconceivable error messages or the notebook gets stuck, choose \"Restart & Clear Output\" in the \"Kernel\" dropdown-menu above.\n",
    "___\n",
    "**Please help us to improve this tool by [emailing us](mailto:ai4ki.dev@gmail.com?subject=ai4ki-tools:%20CORE%20Collection%20Search) your update ideas or error reports.**\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A: Provide API key\n",
    "*Exceute the cell and enter your key in the input field below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = input('Enter your API key: ')\n",
    "print('API key accepted: ', API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B: Import  libraries\n",
    "*You have to excecute the following cell only once at the beginning of a session!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "id": "tclHUXzdfuug"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import urllib.parse\n",
    "sys.path.append('../')\n",
    "\n",
    "from ai4ki_utils.core_utils import *\n",
    "from ai4ki_utils.core_request import *\n",
    "from datetime import datetime\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section I: Query the CORE Collection\n",
    "\n",
    "### Step 1: Formulate search query\n",
    "*Exceute the cell and enter your query in the input field below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "_tFqKbFhF3Np"
   },
   "outputs": [],
   "source": [
    "query = input('Enter query: ') \n",
    "print('Accepted query: ', query)\n",
    "q = urllib.parse.quote(query)\n",
    "\n",
    "# Create list for storing more than 100 results\n",
    "results_store = []\n",
    "\n",
    "# Count number of queries for convenience later\n",
    "n_queries = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Post query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1294,
     "status": "ok",
     "timestamp": 1632155788100,
     "user": {
      "displayName": "ai4ki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggfzsf3wEt__56AE_4PN8hCpiInZFjxJd2dBRcS=s64",
      "userId": "02525147809839202215"
     },
     "user_tz": -120
    },
    "id": "EAFQ3zVoFUNS",
    "outputId": "02e848e3-35a1-4d0d-f6ff-295d72f93739"
   },
   "outputs": [],
   "source": [
    "# Set the maximum number of results to be returned (absolute maximum is 100) \n",
    "limit = 100\n",
    "offset = int((n_queries - 1)*limit)\n",
    "\n",
    "# Construct the URL for the CORE API endpoint\n",
    "url = 'https://api.core.ac.uk/v3/search/works?q=' + q\n",
    "params = {\n",
    "    'offset': str(offset),\n",
    "    'limit': str(limit),\n",
    "    'apiKey': API_KEY\n",
    "}\n",
    "\n",
    "# Make the request and fetch the data\n",
    "status, data = core_request(url, params)\n",
    "if status:\n",
    "    n_papers = len(data['results'])\n",
    "    print('==> Formatting publication data {beg} to {end}:'.format(beg=offset,end=n_papers + offset - 1))\n",
    "    results_form = format_core_data(n_papers, data)\n",
    "    results_store += results_form\n",
    "    df_tmp = pd.DataFrame(results_form) # Create dataframe for display\n",
    "    n_queries += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Preview results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview results\n",
    "n_rows = int(input('Enter number of rows to display: ')) \n",
    "print('==> Displaying first {n} rows: '.format(n=n_rows))\n",
    "\n",
    "df_tmp.head(n_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPAbK22Go4Rg"
   },
   "source": [
    "*If you want to export more than 100 results, repeat step 2 before moving on to steps 4 and 5!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Bulk download available PDFs\n",
    "*NOTE: By default, the PDFs of all results are downloaded (if available). If you only want the first `n_down`, change the parameter below accordingly.*<br>\n",
    "*The parameter `fraction` controls how many characters of the publication title are used for the PDF name.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download PDFs from CORE \n",
    "core_download(results_store, dir_path='./results_pdf', n_down=limit, fraction=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Write results to Excel file  \n",
    "*Note that, after running the following cell, your query results will be deleted from memory!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "KC2jUAwxauGn"
   },
   "outputs": [],
   "source": [
    "XCL_XTNSN, JSN_XTNSN, BBT_XTNSN = '.xlsx', '.json', '.bib'\n",
    "time_stamp = datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")\n",
    "outfile = \"MyCORE_Search_\" + str(time_stamp)\n",
    "\n",
    "# Export results to EXCEL file\n",
    "df_out = pd.DataFrame(results_store)\n",
    "df_out.to_excel(join('./results_excel', outfile+XCL_XTNSN), engine='openpyxl', index=False)\n",
    "\n",
    "# Export BibTex-Data to .bib-file\n",
    "bibtex_data = '\\n\\n'.join([item['BibTex'] for item in results_store if item['BibTex'] is not None])\n",
    "with open(join('./results_bibtex',outfile+BBT_XTNSN), 'w', encoding='utf-8') as f:\n",
    "    f.write(bibtex_data)\n",
    "\n",
    "# Export results to JSON file\n",
    "with open(join('./results_json', outfile+JSN_XTNSN), 'w', encoding='utf-8') as f:\n",
    "    json.dump(results_store, f)\n",
    "\n",
    "#Delete variables for next run\n",
    "del data, df_out, df_tmp, n_queries, n_papers, outfile, q, query, results_form, results_store, status, url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section II: Perform multiple queries in one batch\n",
    "\n",
    "### Step 1: Load your queries\n",
    "*Provide your queries in a `.txt`-file with one line for each query. Run the following cell to load your queries.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and read queries file\n",
    "with open('CORE_queries_abstract.txt', 'r', encoding='utf-8') as f:\n",
    "    user_queries = f.readlines()\n",
    "# Strip leading and trailing spaces and newline char; replace space with proper URL encoding\n",
    "queries = [q.strip() for q in user_queries]\n",
    "for i,q in enumerate(user_queries): print('Query {}: {}'.format(i,q.strip()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Compare the queries (optional)\n",
    "*Run the following cell to get the number of papers for each query and indictators for how a pair of queries compares for the first 100 results.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = comp_mult_queries(queries, API_KEY, min_match=0.7, min_rbo=0.5, p_value=0.97)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation of the RBO value:**<br>\n",
    "\n",
    "*Rank Biased Overlap (RBO) is a measure of similarity between two ranked lists, which don't necessarily share the same items. `RBO=0` means no, `RBO=1` means perfect overlap between two lists. The `p_value` is a measure of how much the first `n` results contribute to the RBO-value. We use a `p_value` of 0.97, which means that the top 10 results contribute roughly 50% to the RBO measure.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1: Discard redundant queries\n",
    "Based on the results of the comparison, you can discard queries, which return redundant results. In the first line of following cell, enter the numbers of the queries you want to discard. Then run the cell to delete the chosen queries from the list `queries`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_queries = [2,5,8]\n",
    "for d in delete_queries:\n",
    "    queries.pop(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Process the queries\n",
    "*Run the following cell to process your queries.<br>\n",
    "The results of each query is stored in a separate Excel-, JSON-, and BibTex-files named `MyCORE_Search_[query i]_[current date_time].*`.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each query, set the number of papers to download.\n",
    "limit = 100 # absolute maximum: 100\n",
    "offset = 0\n",
    "\n",
    "# Store query parameters in directory\n",
    "params = {\n",
    "    'offset': str(offset),\n",
    "    'limit': str(limit),\n",
    "    'apiKey': API_KEY\n",
    "}\n",
    "\n",
    "# For each query, make the request and fetch the data\n",
    "proc_mult_queries(queries, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Semantic_Scholar_API.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:ai4ki]",
   "language": "python",
   "name": "conda-env-ai4ki-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
