{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b032941",
   "metadata": {},
   "source": [
    "# Literature Search with Google Scholar \n",
    "\n",
    "*Last updated: 01/21/2022*\n",
    "\n",
    "This notebook allows you to query [Google Scholar](https://scholar.google.com/). \n",
    "\n",
    "Since Google doesn't like bots, it might block this appliaction occasionally. When this happens, you can either try using a different IP address (see step 1.1 below) or go grab a coffee and wait it out. In any case, don't overdo it. If you're in an early phase of your research, consider using Google Scholar directly for experimenting with different search queries. We also limit each search query to return only the first 100 results (sorted by relevance). \n",
    "\n",
    "The result of your query is stored in different formats: an Excel- and a JSON-file with the full publication data, and a `.bib`-file with only the BibTex data for each publication (if available). You will need the JSON-files, if you later want to merge results using the notebook `Merge_Inspect_Select.ipynb`. The files are named `MyGS_Search_[current date_time].xlsx/.json/.bib`. You will find the files on the left navigation pane in the folder `results`. \n",
    "\n",
    "## Searching with Google Scholar\n",
    "\n",
    "While Google Scholar does support the use of certain search operators, it is not possible to formulate complex queries by combining and grouping multiple Boolean operators. The best way to formulate your query is to use Google Scholar's Advanced Search (AS) option. Go to the end of this notebook, to learn how to transfer a query constructed with AS to this application.\n",
    "\n",
    "\n",
    "## Working with Jupyter notebooks\n",
    "\n",
    "In case you are not familiar with Jupyter notebooks, this is how to go about it: In order to execute a piece of code, click inside a cell (the ones with `[]` to the left) and press Shift+Enter. Wait until the cell is done--that's when the `*` in `[]` turned into a number--and move on to the next cell.\n",
    "\n",
    "If you get inconceivable error messages or the notebook gets stuck, choose \"Restart & Clear Output\" in the \"Kernel\" dropdown-menu above and start afresh. \n",
    "___\n",
    "**Please help us to improve this tool by [emailing us](mailto:ai4ki.dev@gmail.com?subject=ai4ki-tools:%20Google%20Scholar%20Search) your update ideas or error reports.**\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0eb687c",
   "metadata": {},
   "source": [
    "## Step 1: Import some libraries\n",
    "*You have to excecute the following cell only once at the beginning of a session!*<br>\n",
    "*Note: If it throws an error, simply excecute the cell again!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f655e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from ai4ki_utils.gs_utils import format_gs_data\n",
    "from datetime import datetime\n",
    "from os.path import join\n",
    "from scholarly import scholarly, ProxyGenerator\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3165957a",
   "metadata": {},
   "source": [
    "### 1.1: Use a proxy server (optional)\n",
    "*If you receive the error* `MaxTriesExceededException` *after executing step 2, change `USE_PROXY` to `True`, run the cell, and try your query again.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e068ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the following variable to 'True' if you want to use a proxy server\n",
    "USE_PROXY = False\n",
    "\n",
    "if USE_PROXY:\n",
    "    print('...connetcting to proxy server--please be patient')\n",
    "    pg = ProxyGenerator()\n",
    "    pg.FreeProxies()\n",
    "    scholarly.use_proxy(pg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f626478f",
   "metadata": {},
   "source": [
    "## Step 2: Formulate search query\n",
    "### 2.1: Select publication year range\n",
    "*In the cell below, change `start_year` and `end_year` to the desired values. Set them to `None`, if you don't want to limit your search.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f73d356",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = None\n",
    "end_year = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ef97ad",
   "metadata": {},
   "source": [
    "### 2.2: Enter query string\n",
    "*Exceute the cell and enter your query string in the input field below.*<br>\n",
    "*Be patient as it might take some time to connect to proxy server*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6eca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = input('Enter query: ') \n",
    "if len(query) < 256:  \n",
    "    print('Accepted query: ', query)\n",
    "\n",
    "    # Define search query generator object\n",
    "    search_query = scholarly.search_pubs(query, year_low=start_year, year_high=end_year)\n",
    "else:\n",
    "    print('ERROR: Your search string is too long--has {} chars, must have less than 256!'.format(len(query)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60677128",
   "metadata": {},
   "source": [
    "## Step 3: Post query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fd2861",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set maximum number of results (don't change this!)\n",
    "MAX_PUBS = 100\n",
    "\n",
    "pub_counter = 0 \n",
    "results = []\n",
    "for pub in tqdm(search_query):\n",
    "    pub_counter += 1\n",
    "    results.append(pub)\n",
    "    if pub_counter == MAX_PUBS: break\n",
    "        \n",
    "print('Fetched {n_pubs} publications from Google Scholar'.format(n_pubs=pub_counter))\n",
    "\n",
    "# Reformat data for pretty EXCEl dump\n",
    "print('==> Reformatting publication data:')\n",
    "results_form = format_gs_data(pub_counter, results)\n",
    "df = pd.DataFrame(results_form)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863971ea",
   "metadata": {},
   "source": [
    "## Step 4: Preview results (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0860262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview results\n",
    "n_rows = int(input('Enter number of rows to display: ')) \n",
    "print('==> Displaying first {n} rows: '.format(n=n_rows))\n",
    "df.head(n_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6978d04b",
   "metadata": {},
   "source": [
    "## Step 5: Write results to Excel file  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dc7014",
   "metadata": {},
   "outputs": [],
   "source": [
    "XCL_XTNSN, JSN_XTNSN, BBT_XTNSN = '.xlsx', '.json', '.bib'\n",
    "time_stamp = datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")\n",
    "filename = \"MyGS_Search_\" + str(time_stamp)\n",
    "out_dir = '../results'\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "# Export results to EXCEL file\n",
    "df.to_excel(join(out_dir, filename+XCL_XTNSN), engine='openpyxl', index=False)\n",
    "\n",
    "# Export BibTex-Data to .bib-file\n",
    "bibtex_data = '\\n\\n'.join([item['BibTex'] for item in results_form if item['BibTex'] is not None])\n",
    "with open(join(out_dir, filename+BBT_XTNSN), 'w', encoding='utf-8') as f:\n",
    "    f.write(bibtex_data)\n",
    "    \n",
    "# Export results to JSON file\n",
    "with open(join(out_dir, filename+JSN_XTNSN), 'w', encoding='utf-8') as f:\n",
    "  json.dump(results_form, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc6f63b",
   "metadata": {},
   "source": [
    "## Step 7: Perpare next query\n",
    "*Execute the following cell, if you want to start a new query. Note that, after exceuting this cell, the results of your previous query will be lost!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36f77ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df, pub_counter, query, results, results_form, search_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28741c87",
   "metadata": {},
   "source": [
    "## Brief guide to advanced search with Google Scholar\n",
    "\n",
    "Go to [Google Scholar](https://scholar.google.com) and select \"Advanced Search\" in the top-left menu. Construct your query by filling out the appropriate fields and hit search. In the search bar at the top of the results page you find the search string that corresponds to your query. Copy this string and use it as input in step 2 above. \n",
    "\n",
    "Note that you can use the asterisk (\\*) as a placeholder for unknown or wildcard terms, for example `\"bayesian * learning\"` (returns papers with, for example, 'bayesian deep learning'). However, don't use the asterisk to find word variations; GS search does this automatically.\n",
    "\n",
    "In case you want to contruct your query manually, be aware that Google Scholar doesn't recognize the AND-operator. Use space or '+' instead!\n",
    "\n",
    "---\n",
    "*Note: Scholarly has the option to use a custom Google Scholar URL (module: `search_pubs_custom_url(url: str)`). We plan to implement this in the future so that the above detour won't be necessary.*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a948f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ai4ki]",
   "language": "python",
   "name": "conda-env-ai4ki-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
